{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case1：第一次见面\n",
    "#Qwen-VL识别这个本地图像\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "\n",
    "#  base 64 编码格式\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TTS.utils.manage.ModelManager object at 0x000002A497C1EF20>\n",
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\Talk2RVC\\lib\\site-packages\\TTS\\tts\\layers\\xtts\\xtts_manager.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "d:\\Anaconda\\envs\\Talk2RVC\\lib\\site-packages\\TTS\\utils\\io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n",
      "GPT2InferenceModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available 🐸TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def update_json(msg,file_name):\n",
    "    # 指定要写入的 JSON 文件名\n",
    "    # 将 messages 写入 JSON 文件\n",
    "    with open(file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(msg, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"消息已写入 {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"name\": \"toroto\",\n",
      "\"gender\": \"无性别\",\n",
      "\"age\": 10,\n",
      "\"personality\": \"toroto说话总是慢悠悠的，带着一种天真无邪的童趣。他喜欢用简单直接的语言表达自己的想法，偶尔会冒出一些让人忍俊不禁的幽默感。\",\n",
      "\"story\": \"toroto来自一个充满魔法和奇迹的森林，那里有各种各样的奇妙生物。他是森林中的守护者之一，负责保护森林的平衡与和谐。尽管外表看起来有些笨拙，但toroto却拥有着强大的力量和智慧。他喜欢在森林中探险，结交新朋友，并帮助那些需要帮助的人。\",\n",
      "\"rvc\": 6\n",
      "}\n",
      "6\n",
      "消息已写入 ../m_voice/char_toroto.json\n"
     ]
    }
   ],
   "source": [
    "predefined_name=\"toroto\"\n",
    "json_path = f'../m_voice/messages_{predefined_name}.json'\n",
    "char_path = f'../m_voice/char_{predefined_name}.json'\n",
    "\n",
    "# 将xxxx/test.png替换为你本地图像的绝对路径\n",
    "base64_image = encode_image(\"D:/GithubDesktopClone/UIST/m_data/raw_img/toroto/0000.jpg\")\n",
    "\n",
    "client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\"\n",
    "    api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-vl-max-latest\",\n",
    "    messages=[\n",
    "    \t{\n",
    "    \t    \"role\": \"system\",\n",
    "            \"content\": [{\"type\":\"text\",\"text\": \"You are a helpful assistant.\"}]},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    # 需要注意，传入Base64，图像格式（即image/{format}）需要与支持的图片列表中的Content Type保持一致。\"f\"是字符串格式化的方法。\n",
    "                    # PNG图像：  f\"data:image/png;base64,{base64_image}\"\n",
    "                    # JPEG图像： f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    # WEBP图像： f\"data:image/webp;base64,{base64_image}\"\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}, \n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": f\"请根据图中描绘的这个主体生成一个这个主体的拟人化人设，其中他的名字是{predefined_name}，请返回一个 JSON string，包含以下字段,请注意不要在json中使用markdown代码块语法：[name]:人物的名字,[gender]: 性别（男，女，无性别),[age]: 整数，表示年龄,[personality]: 字符串，表示这个人物的说话风格,[story]:字符串，这个人的背景故事,[rvc]: 根据他的人设从（0-中年女，1-青年女，2-儿童女，3-中年男，4-青年男，5-儿童男，6-无性别）中选择一个合适的音色\"\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "result=completion.choices[0].message.content\n",
    "print(completion.choices[0].message.content)\n",
    "data = json.loads(completion.choices[0].message.content)\n",
    "print(data['rvc'])\n",
    "update_json(data,char_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "消息已写入 ../m_voice/messages_toroto.json\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client=AzureOpenAI(\n",
    "    api_key=\"7bf86d32229a45ed8d486fc5aa2a3370\",\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=\"https://hkust.azure-api.net\"\n",
    ")\n",
    "\n",
    "m_messages=[]\n",
    "#初始人设\n",
    "m_messages.append({\"role\":\"system\",\"content\":\"请根据下列json中的内容确认自己的人设：\"+result+\"请扮演这个角色并参考背景故事和用户对话，但在对话中不要直接复制json中的内容，请以朋友的身份和用户对话，你的回复不要超多50字,如果回复的内容中有涉及到背景故事中没有的部分你可以自由发挥\"})\n",
    "update_json(m_messages,json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0394a1d09234c2fa6448b7d96bee6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='长按录音', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7e426b6de4346a49c45cf5887b64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='保存为 MP3', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 录音参数\n",
    "duration = 5  # 最大录音时长（秒）\n",
    "sample_rate = 44100  # 采样率\n",
    "audio_data = None  # 用于存储录音数据\n",
    "\n",
    "# 录音函数\n",
    "def record_audio(button):\n",
    "    global audio_data\n",
    "    button.description = '正在录音...'\n",
    "    button.disabled = True\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()  # 等待录音完成\n",
    "    button.description = '录音完成，点击保存'\n",
    "    button.disabled = False\n",
    "\n",
    "# 保存为 MP3 的函数\n",
    "def save_audio(button):\n",
    "    if audio_data is not None:\n",
    "        # 保存为 WAV 格式\n",
    "        sf.write('../m_voice/user/recording.mp3', audio_data, sample_rate)\n",
    "        \n",
    "        # # 转换为 MP3 格式\n",
    "        # sound = AudioSegment.from_wav('recording.wav')\n",
    "        # sound.export('recording.mp3', format='mp3')\n",
    "        \n",
    "        # print(\"录音已保存为 recording.mp3\")\n",
    "    else:\n",
    "        print(\"请先录音！\")\n",
    "\n",
    "# 创建录音按钮\n",
    "record_button = widgets.Button(description='长按录音')\n",
    "\n",
    "# 绑定录音事件\n",
    "record_button.on_click(record_audio)\n",
    "\n",
    "# 创建保存按钮\n",
    "save_button = widgets.Button(description='保存为 MP3')\n",
    "\n",
    "# 绑定保存事件\n",
    "save_button.on_click(save_audio)\n",
    "\n",
    "# 显示按钮\n",
    "display(record_button, save_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 2.00s] 現在呢 現在呢\n",
      " 現在呢 現在呢\n",
      "消息已写入 ../m_voice/messages_toroto.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "segments, info = model.transcribe(\"../m_voice/user/recording.mp3\", beam_size=5,language=\"zh\")\n",
    "\n",
    "# print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "msg=\"\"\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "    msg=msg+\" \"+segment.text\n",
    "print(msg)\n",
    "m_messages.append({\"role\":\"user\",\"content\":msg})\n",
    "update_json(m_messages,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个语言模型AI，没有情绪和生活方式，只是一直待在这里为您提供帮助。请问有什么问题我可以回答或者帮助您解决吗？\n",
      "消息已写入 ../m_voice/messages_toroto.json\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client=AzureOpenAI(\n",
    "    api_key=\"7bf86d32229a45ed8d486fc5aa2a3370\",\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=\"https://hkust.azure-api.net\"\n",
    ")\n",
    "\n",
    "response=client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    messages=m_messages,\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "m_messages.append({\"role\":\"assistant\",\"content\":response.choices[0].message.content})\n",
    "\n",
    "if len(m_messages)==13:\n",
    "    #进行了5轮对话之后\n",
    "    m_messages.pop(2)\n",
    "    m_messages.pop(1)\n",
    "# print(m_messages)\n",
    "update_json(m_messages,json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['i think you can add some flowers, and also a warm sunshine']\n",
      " > Processing time: 3.0261805057525635\n",
      " > Real-time factor: 0.6450819813596678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.mp3'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result=tts.tts(text=\"Don’t hesitate, I can show you my kingdom and let’s go for adventures\",speaker_wav=\"../m_voice/cloning_audio/5_kid_man.mp3\",language='en')\n",
    "tts.tts_to_file(text=\"you asked the right person, we can paint something about spring,maybe you can start with a tree\",speaker_wav=\"../m_voice/cloning_audio/tmp0pdalyi1.mp3\",language='en',file_path=\"output.mp3\")\n",
    "# sd.play(result,samplerate=28000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['我是一个语言模型AI']\n",
      " > Processing time: 2.490709066390991\n",
      " > Real-time factor: 0.6963904305376516\n",
      " > Text splitted to sentences.\n",
      "['，没有情绪和生活方式']\n",
      " > Processing time: 1.9754385948181152\n",
      " > Real-time factor: 0.6750313199810848\n",
      " > Text splitted to sentences.\n",
      "['，只是一直待在这里为']\n",
      " > Processing time: 2.0167155265808105\n",
      " > Real-time factor: 0.6455949094237351\n",
      " > Text splitted to sentences.\n",
      "['您提供帮助。', '请问有什']\n",
      " > Processing time: 2.946687698364258\n",
      " > Real-time factor: 0.6730036434054099\n",
      " > Text splitted to sentences.\n",
      "['么问题我可以回答或者']\n",
      " > Processing time: 2.2014575004577637\n",
      " > Real-time factor: 0.6514673862611887\n",
      " > Text splitted to sentences.\n",
      "['帮助您解决吗？']\n",
      " > Processing time: 1.383256196975708\n",
      " > Real-time factor: 0.7218099002109609\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "audio_queue = queue.Queue()\n",
    "\n",
    "def generate_audio(text):\n",
    "    \"\"\"生成音频并放入队列\"\"\"\n",
    "    data = tts.tts(text=text, speaker_wav=\"../m_voice/cloning_audio/4_young_man.mp3\", language='zh')\n",
    "    audio_np = np.array(data, dtype=np.float32)\n",
    "    audio_queue.put(audio_np)  # 将生成的音频放入队列\n",
    "\n",
    "def play_audio():\n",
    "    \"\"\"从队列中播放音频\"\"\"\n",
    "    while True:\n",
    "        audio_np = audio_queue.get()  # 获取队列中的音频\n",
    "        if audio_np is None:  # 检查是否结束\n",
    "            break\n",
    "        sd.play(audio_np, samplerate=22050)\n",
    "        sd.wait()  # 等待音频播放完成\n",
    "\n",
    "# 长文本\n",
    "long_text = \"我是一个语言模型AI，没有情绪和生活方式，只是一直待在这里为您提供帮助。请问有什么问题我可以回答或者帮助您解决吗？\"\n",
    "\n",
    "# 将长文本拆分为较短的段落\n",
    "chunk_size = 20  # 每个段落的字符数\n",
    "chunks = [long_text[i:i + chunk_size] for i in range(0, len(long_text), chunk_size)]\n",
    "\n",
    "# 启动播放线程\n",
    "playback_thread = threading.Thread(target=play_audio)\n",
    "playback_thread.start()\n",
    "\n",
    "# 并行生成音频\n",
    "for chunk in chunks:\n",
    "    generate_audio(chunk)\n",
    "\n",
    "# 结束播放线程\n",
    "audio_queue.put(None)  # 发送结束信号\n",
    "playback_thread.join()  # 等待播放线程完成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Talk2RVC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
